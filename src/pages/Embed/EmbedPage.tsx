// src/pages/Embed/EmbedPage.tsx
// The LiveKit-powered voice widget â€” appears inside an iframe on customer websites.
// Mirrors KTX patterns: WelcomeView â†’ SessionView (AudioVisualizer + Transcript + AgentControlBar)
import { useState, useRef, useEffect, useCallback } from "react";
import { useSearchParams, useParams } from "react-router-dom";
import {
  Room,
  RoomEvent,
  ParticipantEvent,
  RemoteParticipant,
  type RemoteTrackPublication,
  type RemoteTrack,
  Track,
  TrackEvent,
} from "livekit-client";
import { getEmbedToken } from "../../services/services";
import type { EmbedTokenResponse, TranscriptEntry } from "../../global";
import "./EmbedPage.css";

// â”€â”€â”€ AudioVisualizer component â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const AuraVisualizer = ({ speaking }: { speaking: boolean }) => (
  <div className={`viz-aura ${speaking ? "speaking" : ""}`}>ğŸ™ï¸</div>
);

// â”€â”€â”€ Main EmbedPage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
type Phase = "welcome" | "connecting" | "session" | "ended";

const EmbedPage = () => {
  const { slug } = useParams<{ slug: string }>();
  const [searchParams] = useSearchParams();
  const embedToken = searchParams.get("token") || "";

  const [phase, setPhase] = useState<Phase>("welcome");
  const [error, setError] = useState("");
  const [agentName, setAgentName] = useState("Voice Agent");
  const [welcomeMsg, setWelcomeMsg] = useState(
    "Hi! Click the button below to start talking.",
  );
  const [agentSpeaking, setAgentSpeaking] = useState(false);
  const [micMuted, setMicMuted] = useState(false);
  const [transcript, setTranscript] = useState<TranscriptEntry[]>([]);
  const [chatInput, setChatInput] = useState("");
  const [lastSpoken, setLastSpoken] = useState("");

  const roomRef = useRef<Room | null>(null);
  const transcriptRef = useRef<HTMLDivElement>(null);

  // Auto-scroll transcript
  useEffect(() => {
    if (transcriptRef.current) {
      transcriptRef.current.scrollTop = transcriptRef.current.scrollHeight;
    }
  }, [transcript]);

  // â”€â”€ Start call â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const startCall = useCallback(async () => {
    if (!embedToken) {
      setError("No embed token found in URL.");
      return;
    }
    setPhase("connecting");
    setError("");

    try {
      const res = await getEmbedToken(embedToken);
      const data: EmbedTokenResponse = res.data;
      setAgentName(data.agentName || slug || "Voice Agent");
      setWelcomeMsg(data.welcomeMessage || welcomeMsg);

      const room = new Room({
        adaptiveStream: true,
        dynacast: true,
      });
      roomRef.current = room;

      // â”€â”€ Room events â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      room.on(RoomEvent.Connected, async () => {
        setPhase("session");
        // Enable microphone
        await room.localParticipant.setMicrophoneEnabled(true);
      });

      room.on(RoomEvent.Disconnected, () => {
        setPhase("ended");
      });

      // â”€â”€ Track subscribed â€” play agent audio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      room.on(
        RoomEvent.TrackSubscribed,
        (
          track: RemoteTrack,
          _pub: RemoteTrackPublication,
          _participant: RemoteParticipant,
        ) => {
          if (track.kind === Track.Kind.Audio) {
            track.attach();
            track.on(TrackEvent.AudioSilenceDetected, () =>
              setAgentSpeaking(false),
            );

            // Basic speaking detection via audio track
            const mediaStream = new MediaStream([track.mediaStreamTrack]);
            const audioCtx = new AudioContext();
            const source = audioCtx.createMediaStreamSource(mediaStream);
            const analyser = audioCtx.createAnalyser();
            analyser.fftSize = 256;
            source.connect(analyser);
            const data = new Uint8Array(analyser.frequencyBinCount);

            const detectSpeech = () => {
              analyser.getByteFrequencyData(data);
              const avg = data.reduce((a, b) => a + b, 0) / data.length;
              setAgentSpeaking(avg > 12);
              requestAnimationFrame(detectSpeech);
            };
            detectSpeech();
          }
        },
      );

      // â”€â”€ Data messages from agent (transcript entries) â”€â”€â”€â”€â”€â”€â”€
      room.on(RoomEvent.DataReceived, (payload: Uint8Array) => {
        try {
          const text = new TextDecoder().decode(payload);
          const msg = JSON.parse(text);
          if (msg.type === "transcript") {
            const entry: TranscriptEntry = {
              role: msg.role as "user" | "agent",
              text: msg.text,
              timestamp: new Date().toISOString(),
            };
            setTranscript((prev) => [...prev, entry]);
            if (msg.role === "agent") setLastSpoken(msg.text);
          }
        } catch {
          // Non-JSON data packets are ignored
        }
      });

      // â”€â”€ Local speaking state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      room.localParticipant.on(
        ParticipantEvent.IsSpeakingChanged,
        (_speaking: boolean) => {
          // Could be used for local mic indicator
        },
      );

      // Connect to LiveKit room
      await room.connect(data.livekitUrl, data.livekitToken);
    } catch (err: any) {
      setError(
        err?.response?.data?.error || err?.message || "Failed to start call.",
      );
      setPhase("welcome");
    }
  }, [embedToken, slug]);

  // â”€â”€ Toggle mic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const toggleMic = async () => {
    if (!roomRef.current) return;
    const enabled = !micMuted;
    await roomRef.current.localParticipant.setMicrophoneEnabled(enabled);
    setMicMuted(!enabled);
  };

  // â”€â”€ Send text message to agent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const sendText = async () => {
    const text = chatInput.trim();
    if (!text || !roomRef.current) return;
    setChatInput("");

    // Add to local transcript
    setTranscript((prev) => [
      ...prev,
      {
        role: "user",
        text,
        timestamp: new Date().toISOString(),
      },
    ]);

    // Send via LiveKit data channel to the Python agent
    const encoder = new TextEncoder();
    const payload = encoder.encode(
      JSON.stringify({ type: "chat_input", text }),
    );
    await roomRef.current.localParticipant.publishData(payload, {
      reliable: true,
      destinationIdentities: [],
    });
  };

  // â”€â”€ End call â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const endCall = async () => {
    if (roomRef.current) {
      await roomRef.current.disconnect();
    }
    setPhase("ended");
  };

  // â”€â”€â”€ Render â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  return (
    <div className="embed-page">
      {/* â”€â”€ WELCOME VIEW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */}
      {(phase === "welcome" || phase === "connecting") && (
        <div className="embed-welcome">
          <div className="embed-logo">ğŸ™ï¸</div>
          <div className="embed-agent-name">{agentName}</div>
          <p className="embed-welcome-msg">{welcomeMsg}</p>

          {error && <p className="embed-error">{error}</p>}

          <button
            id="embed-start-call"
            className="embed-start-btn"
            onClick={startCall}
            disabled={phase === "connecting"}
          >
            {phase === "connecting" ? (
              "Connectingâ€¦"
            ) : (
              <>
                <span className="pulse-ring" />
                ğŸ™ï¸ Start Talking
              </>
            )}
          </button>

          <div className="embed-powered">
            Powered by VoiceAgent Â· LiveKit Â· Gemini
          </div>
        </div>
      )}

      {/* â”€â”€ SESSION VIEW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */}
      {phase === "session" && (
        <div className="embed-session">
          {/* Header */}
          <div className="embed-session-header">
            <span className="embed-session-title">{agentName}</span>
            <span className="embed-live-dot">LIVE</span>
          </div>

          {/* Audio Visualizer */}
          <div className="audio-visualizer-container">
            <AuraVisualizer speaking={agentSpeaking} />
          </div>

          {/* Last spoken by agent */}
          <p className="agent-spoken-text">{agentSpeaking ? lastSpoken : ""}</p>

          {/* Transcript */}
          <div className="embed-transcript" ref={transcriptRef}>
            {transcript.map((msg, idx) => (
              <div key={idx} className={`transcript-msg ${msg.role}`}>
                <div className="transcript-bubble">{msg.text}</div>
              </div>
            ))}
          </div>

          {/* Controls */}
          <div className="embed-controls">
            {/* Chat input row */}
            <div className="embed-chat-row">
              <textarea
                id="embed-chat-input"
                className="embed-chat-input"
                rows={1}
                placeholder="Type a messageâ€¦"
                value={chatInput}
                onChange={(e) => setChatInput(e.target.value)}
                onKeyDown={(e) => {
                  if (e.key === "Enter" && !e.shiftKey) {
                    e.preventDefault();
                    sendText();
                  }
                }}
              />
              <button
                id="embed-send-btn"
                className="embed-send-btn"
                onClick={sendText}
                disabled={!chatInput.trim()}
                title="Send message"
              >
                â†‘
              </button>
            </div>

            {/* Action buttons */}
            <div className="embed-action-row">
              <button
                id="embed-mic-btn"
                className={`embed-mic-btn ${micMuted ? "muted" : ""}`}
                onClick={toggleMic}
              >
                {micMuted ? "ğŸ”‡ Unmute" : "ğŸ™ï¸ Mute"}
              </button>
              <button
                id="embed-end-btn"
                className="embed-end-btn"
                onClick={endCall}
              >
                ğŸ“µ End Call
              </button>
            </div>

            <div className="embed-powered">Powered by VoiceAgent</div>
          </div>
        </div>
      )}

      {/* â”€â”€ ENDED VIEW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */}
      {phase === "ended" && (
        <div className="embed-welcome">
          <div style={{ fontSize: "3rem" }}>âœ…</div>
          <div className="embed-agent-name">Call Ended</div>
          <p className="embed-welcome-msg" style={{ marginBottom: "1.5rem" }}>
            Thank you for using VoiceAgent!
          </p>
          <button
            className="embed-start-btn"
            onClick={() => {
              setPhase("welcome");
              setTranscript([]);
              setLastSpoken("");
              setAgentSpeaking(false);
              setMicMuted(false);
            }}
          >
            Start New Call
          </button>
        </div>
      )}
    </div>
  );
};

export default EmbedPage;
